{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f43d9bd",
   "metadata": {},
   "source": [
    "#Q1\n",
    "\n",
    "An inception network is a deep neural network with an architectural design that consists of repeating components referred to as Inception modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b6555",
   "metadata": {},
   "source": [
    "#Q2\n",
    "\n",
    "An Inception Module is an image model block that aims to approximate an optimal local sparse structure in a CNN. Put simply, it allows for us to use multiple types of filter size, instead of being restricted to a single filter size, in a single image block, which we then concatenate and pass onto the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e924b5",
   "metadata": {},
   "source": [
    "#Q3\n",
    "\n",
    "A 1x1 convolution simply maps an input pixel with all it's channels to an output pixel, not looking at anything around itself. It is often used to reduce the number of depth channels, since it is often very slow to multiply volumes with extremely large depths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d38b5",
   "metadata": {},
   "source": [
    "#Q4\n",
    "\n",
    "Dimensionality reduction removes noise in the data — By keeping only the most important features and removing the redundant features, dimensionality reduction removes noise in the data. This will improve the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634195a",
   "metadata": {},
   "source": [
    "#Q6\n",
    "\n",
    "A residual neural network (ResNet) is an artificial neural network (ANN). It is a gateless or open-gated variant of the HighwayNet, the first working very deep feedforward neural network with hundreds of layers, much deeper than previous neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f5bff",
   "metadata": {},
   "source": [
    "#Q7\n",
    "\n",
    " Skip Connections (or Shortcut Connections) as the name suggests skips some of the layers in the neural network and feeds the output of one layer as the input to the next layers. Skip Connections were introduced to solve different problems in different architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19811350",
   "metadata": {},
   "source": [
    "#Q8\n",
    "\n",
    "A residual block is a stack of layers set in such a way that the output of a layer is taken and added to another layer deeper in the block. The non-linearity is then applied after adding it together with the output of the corresponding layer in the main path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e2e32",
   "metadata": {},
   "source": [
    "#Q9\n",
    "\n",
    "Transfer learning is a technique to help solve this problem. As a concept, it works by transferring as much knowledge as possible from an existing model to a new model designed for a similar task. For example, transferring the more general aspects of a model which make up the main processes for completing a task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0785a23",
   "metadata": {},
   "source": [
    "#Q10\n",
    "\n",
    "Transfer learning is a machine learning method where we reuse a pre-trained model as the starting point for a model on a new task. To put it simply—a model trained on one task is repurposed on a second, related task as an optimization that allows rapid progress when modeling the second task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80c0c2",
   "metadata": {},
   "source": [
    "#Q11\n",
    "\n",
    "Neural networks work by propagating forward inputs, weights and biases. However, it's the reverse process of backpropagation where the network actually learns by determining the exact changes to make to weights and biases to produce an accurate result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b0731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

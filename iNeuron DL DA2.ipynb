{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8978d441",
   "metadata": {},
   "source": [
    "#Q1\n",
    "\n",
    "An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human body's biological neural network, have a layered architecture and each network node (connection point) has the capability to process input and forward output to other nodes in the network.\n",
    "Biological neural networks process information in parallel; this is also true of artificial neural networks. b. Learning in biological neural networks is through past experiences which improve their performance level; this is also true of artificial neural networks.\n",
    "ANN is made of three layers namely input layer, output layer, and hidden layer/s. There must be a connection from the nodes in the input layer with the nodes in the hidden layer and from each hidden layer node with the nodes of the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392b591",
   "metadata": {},
   "source": [
    "#Q2\n",
    "\n",
    "Types of Activation Functions\n",
    "1. Sigmoid Function\n",
    "In an ANN, the sigmoid function is a non-linear AF used primarily in feedforward neural networks. It is a differentiable real function, defined for real input values, and containing positive derivatives everywhere with a specific degree of smoothness. The sigmoid function appears in the output layer of the deep learning models and is used for predicting probability-based outputs. \n",
    "2. Hyperbolic Tangent Function (Tanh)\n",
    "The hyperbolic tangent function, a.k.a., the tanh function, is another type of AF. It is a smoother, zero-centered function having a range between -1 to 1. \n",
    "3. Softmax Function \n",
    "The softmax function is another type of AF used in neural networks to compute probability distribution from a vector of real numbers. This function generates an output that ranges between values 0 and 1 and with the sum of the probabilities being equal to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abb008",
   "metadata": {},
   "source": [
    "#Q3\n",
    "\n",
    "Artificial neural network (ANN) is a computational model that consists of several processing elements that receive inputs and deliver outputs based on their predefined activation functions.\n",
    "ANN is made of three layers namely input layer, output layer, and hidden layer/s. There must be a connection from the nodes in the input layer with the nodes in the hidden layer and from each hidden layer node with the nodes of the output layer. The input layer takes the data from the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4afa3",
   "metadata": {},
   "source": [
    "#Q4\n",
    "\n",
    "Basically, learning means to do and adapt the change in itself as and when there is a change in environment. ANN is a complex system or more precisely we can say that it is a complex adaptive system, which can change its internal structure based on the information passing through it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377feb6",
   "metadata": {},
   "source": [
    "#Q5\n",
    "\n",
    "Backpropagation, or backward propagation of errors, is an algorithm that is designed to test for errors working back from output nodes to input nodes. It is an important mathematical tool for improving the accuracy of predictions in data mining and machine learning.\n",
    "The biggest disadvantages of backpropagation are: Backpropagation could be rather sensitive to noisy data and irregularity. The performance of backpropagation relies very heavily on the training data. Backpropagation needs a very large amount of time for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7480f",
   "metadata": {},
   "source": [
    "#Q6\n",
    "\n",
    "One main part of the algorithm is adjusting the interconnection weights. This is done using a technique termed as Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0414ae",
   "metadata": {},
   "source": [
    "#Q7\n",
    "\n",
    "Step – 1: Forward Propagation. Step – 2: Backward Propagation. Step – 3: Putting all the values together and calculating the updated weight value.\n",
    "            Basically, by adding more hidden layers / more neurons per layer you add more parameters to the model. Hence you allow the model to fit more complex functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda6a1b",
   "metadata": {},
   "source": [
    "#Q8\n",
    "\n",
    "1. This simple artificial neuron is called a perceptron. Data enters the perceptron, undergoes mathematical calculations, and then leaves the perceptron. Artificial neurons can be arranged in several layers so that each layer performs different calculations.\n",
    "2. A multilayer perceptron (MLP) is a fully connected class of feedforward artificial neural network (ANN). The term MLP is used ambiguously, sometimes loosely to mean any feedforward ANN, sometimes strictly to refer to networks composed of multiple layers of perceptrons\n",
    "3. Deep learning is a type of machine learning and artificial intelligence (AI) that imitates the way humans gain certain types of knowledge. Deep learning is an important element of data science, which includes statistics and predictive modeling.\n",
    "4. In machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbb2a9",
   "metadata": {},
   "source": [
    "#Q9\n",
    "\n",
    "1. The activation function compares the input value to a threshold value. If the input value is greater than the threshold value, the neuron is activated. It's disabled if the input value is less than the threshold value, which means its output isn't sent on to the next or hidden layer.\n",
    "2. In case of simple binary classification, a step function is appropriate. Sigmoids can be useful when building more biologically realistic networks by introducing noise or uncertainty.\n",
    "3. MLPs are neural networks with at least three layers while DNNs are neural networks with additional or deeper layers. DNNs and MLPs are both capable of performing such complex tasks as compared to traditional machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77374223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

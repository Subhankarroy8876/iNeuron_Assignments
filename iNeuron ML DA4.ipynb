{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e762a2d5",
   "metadata": {},
   "source": [
    "#Q1\n",
    "\n",
    "Step 1: Collect Data\n",
    "\n",
    "Given the problem you want to solve, you will have to investigate and obtain data that you will use to feed your machine. The quality and quantity of information you get are very important since it will directly impact how well or badly your model will work. You may have the information in an existing database or you must create it from scratch. If it is a small project you can create a spreadsheet that will later be easily exported as a CSV file. It is also common to use the web scraping technique to automatically collect information from various sources such as APIs.\n",
    "Step 2: Prepare the data\n",
    "\n",
    "This is a good time to visualize your data and check if there are correlations between the different characteristics that we obtained. It will be necessary to make a selection of characteristics since the ones you choose will directly impact the execution times and the results. You can also reduce dimensions by applying PCA if necessary.\n",
    "\n",
    "Additionally, you must balance the amount of data we have for each result -class- so that it is significant as the learning may be biased towards a type of response and when your model tries to generalize knowledge it will fail.\n",
    "\n",
    "You must also separate the data into two groups: one for training and the other for model evaluation which can be divided approximately in a ratio of 80/20 but it can vary depending on the case and the volume of data we have.\n",
    "\n",
    "At this stage, you can also pre-process your data by normalizing, eliminating duplicates, and making error corrections.\n",
    "\n",
    "Step 3: Choose the model\n",
    "\n",
    "There are several models that you can choose according to the objective that you might have: you will use algorithms of classification, prediction, linear regression, clustering, i.e. k-means or K-Nearest Neighbor, Deep Learning, i.e Neural Networks, Bayesian, etc.\n",
    "    Step 4 Train your machine model\n",
    "\n",
    "You will need to train the datasets to run smoothly and see an incremental improvement in the prediction rate. Remember to initialize the weights of your model randomly -the weights are the values that multiply or affect the relationships between the inputs and outputs- which will be automatically adjusted by the selected algorithm the more you train them.\n",
    "\n",
    "Step 5: Evaluation\n",
    "\n",
    "You will have to check the machine created against your evaluation data set that contains inputs that the model does not know and verify the precision of your already trained model. If the accuracy is less than or equal to 50%, that model will not be useful since it would be like tossing a coin to make decisions. If you reach 90% or more, you can have good confidence in the results that the model gives you.\n",
    "\n",
    "Step 6: Parameter Tuning\n",
    "\n",
    "If during the evaluation you did not obtain good predictions and your precision is not the minimum desired, it is possible that you have overfitting -or underfitting problems and you must return to the training step before making a new configuration of parameters in your model. You can increase the number of times you iterate your training data- termed epochs. Another important parameter is the one known as the “learning rate”, which is usually a value that multiplies the gradient to gradually bring it closer to the global -or local- minimum to minimize the cost of the function.\n",
    "\n",
    "Increasing your values by 0.1 units from 0.001 is not the same as this can significantly affect the model execution time. You can also indicate the maximum error allowed for your model. You can go from taking a few minutes to hours, and even days, to train your machine. These parameters are often called Hyperparameters. This “tuning” is still more of an art than a science and will improve as you experiment. There are usually many parameters to adjust and when combined they can trigger all your options. Each algorithm has its own parameters to adjust. To name a few more, in Artificial Neural Networks (ANNs) you must define in its architecture the number of hidden layers it will have and gradually test with more or less and with how many neurons each layer. This will be a work of great effort and patience to give good results.\n",
    "\n",
    "Step 7: Prediction or Inference\n",
    "\n",
    "You are now ready to use your Machine Learning model inferring results in real-life scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32249783",
   "metadata": {},
   "source": [
    "#Q2\n",
    "\n",
    "Almost anything can be turned into DATA. Building a deep understanding of the different data types is a crucial prerequisite for doing Exploratory Data Analysis (EDA) and Feature Engineering for Machine Learning models. You also need to convert data types of some variables in order to make appropriate choices for visual encodings in data visualization and storytelling.\n",
    "\n",
    "Most data can be categorized into 4 basic types from a Machine Learning perspective: numerical data, categorical data, time-series data, and text.\n",
    "\n",
    "Numerical Data\n",
    "Numerical data is any data where data points are exact numbers. Statisticians also might call numerical data, quantitative data. This data has meaning as a measurement such as house prices or as a count, such as a number of residential properties in Los Angeles or how many houses sold in the past year.\n",
    "\n",
    "Numerical data can be characterized by continuous or discrete data. Continuous data can assume any value within a range whereas discrete data has distinct values.\n",
    "\n",
    "Categorical Data\n",
    "Categorical data represents characteristics, such as a hockey player’s position, team, hometown. Categorical data can take numerical values. For example, maybe we would use 1 for the colour red and 2 for blue. But these numbers don’t have a mathematical meaning. That is, we can’t add them together or take the average.\n",
    "\n",
    "In the context of super classification, categorical data would be the class label. This would also be something like if a person is a man or woman, or property is residential or commercial.\n",
    "\n",
    "Time Series Data\n",
    "Time series data is a sequence of numbers collected at regular intervals over some period of time. It is very important, especially in particular fields like finance. Time series data has a temporal value attached to it, so this would be something like a date or a timestamp that you can look for trends in time.\n",
    "\n",
    "Text\n",
    "Text data is basically just words. A lot of the time the first thing that you do with text is you turn it into numbers using some interesting functions like the bag of words formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e68e71",
   "metadata": {},
   "source": [
    "#Q3\n",
    "\n",
    "i) Differences Between Categorical & Numerical Data \n",
    "Definitions\n",
    "Categorical data is a type of data that is used to group information with similar characteristics while Numerical data is a type of data that expresses information in the form of numbers. It combines numeric values to depict relevant information while categorical data uses a descriptive approach to express information\n",
    "\n",
    "We can see that the 2 definitions above are different. Therefore, categorical data and numerical data do not mean the same thing.\n",
    "\n",
    "Other Names\n",
    "Categorical data is also called qualitative data while numerical data is also called quantitative data. This is because categorical data is used to qualify information before classifying them according to their similarities.\n",
    "\n",
    "Numerical data is used to express quantitative values and can also perform arithmetic operations which is a quantitative characteristic.\n",
    "\n",
    "Both numerical and categorical data have other names that depict their meaning. But the names are however different from each other.\n",
    "\n",
    "Examples\n",
    " Categorical data examples include personal biodata information—full name, gender, phone number, etc. Numerical data examples include CGPA calculator, interval sale, etc. \n",
    "\n",
    "The examples below are examples of both categorical data and numerical data respectively.\n",
    "\n",
    "What is your hair colour?\n",
    "Blonde\n",
    "Brunette\n",
    "Brown\n",
    "Black\n",
    "Red\n",
    "Types\n",
    "Categorical data is divided into two types, namely; nominal and ordinal data while numerical data is categorised into discrete and continuous data. Continuous data is now further divided into interval data and ratio data.\n",
    "\n",
    "Although they are both of 2 types, these data types are not similar.\n",
    "\n",
    "Data Characteristics\n",
    "The characteristics of categorical data include; lack of a standardized order scale, natural language description, takes numeric values with qualitative properties, and visualized using bar chart and pie chart. \n",
    "\n",
    "Numerical data, on the other hand, has a standardized order scale, numerical description, takes numeric values with numerical properties, and visualized using bar charts, pie charts, scatter plots, etc.\n",
    "\n",
    "User-centred Design\n",
    "Numerical data collection method is more user-centred than categorical data. Most respondents do not want to spend a lot of time filling out forms or surveys which is why questionnaires used to collect numerical data has a lower abandonment rate compared to that of categorical data.\n",
    "\n",
    "This is because categorical data is mostly collected using open-ended questions. \n",
    "\n",
    "Data Collection Methods\n",
    "Categorical data can be collected through different methods, which may differ from categorical data types. For instance, nominal data is mostly collected using open-ended questions while ordinal data is mostly collected using multiple-choice questions.\n",
    "\n",
    "Numerical data, on the other hand, is mostly collected through multiple-choice questions. We observe that it is mostly collected using open-ended questions whenever there is a need for calculation.\n",
    "\n",
    "Data Collection Tools\n",
    "Data collectors and researchers collect numerical data using questionnaires, surveys, interviews, focus groups and observations. Categorical data is collected using questionnaires, surveys, and interviews. \n",
    "\n",
    "Data collection is usually straightforward with categorical data and hence, does not require technical tools like numerical data. For example, numerical data of a participant’s score in different sections of an IQ test may be required to calculate the participant’s IQ.\n",
    "\n",
    "When collected using online forms, this may require some technical additions to the form, unlike categorical data which is simple.\n",
    "\n",
    "Analysis & Interpretation\n",
    "There are 2 methods of performing numerical data analysis, namely; descriptive and inferential statistics. Some examples of these 2 methods include; measures of central tendency, turf analysis, text analysis, conjoint analysis, trend analysis, etc. \n",
    "\n",
    "There are also 2 methods of analyzing categorical data, namely; median and mode. In some cases, we see that ordinal data Is analyzed using univariate statistics, bivariate statistics, regression analysis, etc. which is used as an alternative to calculating mean and standard deviation.\n",
    "\n",
    "Uses\n",
    "Numerical data is mostly used for calculation problems in statistics due to its ability to perform arithmetic operations. For example, when designing a CGPA calculator, one may need to include commands that allow for the addition, subtraction, division, and multiplication. \n",
    "\n",
    "Categorical data, on the other hand, is mostly used for performing research that requires the use of respondent’s personal information, opinion, etc. It is commonly used in business research.\n",
    "\n",
    "ii) dimensionality reduction\n",
    "dimension reduction is the process of reducing the number of random variables under consideration, and can be divided into feature selection and feature extraction.\n",
    "feature selection: you select a subset of the original feature set; while\n",
    "feature extraction: you build a new set of features from the original feature set.\n",
    "Examples of feature extraction: extraction of contours in images, extraction of digrams from a text, extraction of phonemes from recording of spoken text, etc.\n",
    "Feature extraction involves a transformation of the features, which often is not reversible because some information is lost in the process of dimensionality reduction.\n",
    "Feature Selection\n",
    "Feature selection yields a subset of features from the original set of features, which are best representatives of the data. It is an exhaustive search.\n",
    "-In text data, features might be size of characters or some global features of the text. Feature selection will keep only certain features of those.\n",
    "-Feature selection is done in the context of an optimization problem.\n",
    "Dimension Reduction\n",
    "Dimensionality reduction is generic and only depends on the data and not on what you plan to do with it.\n",
    "Assuming a classification problem you select the features that will help you classify your data better, while a dimensionality reduction algorithm is unaware of this and just projects the data into a lower dimensionality space. That in turn can work quite well or not for your classification algorithm.\n",
    "References:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573338b",
   "metadata": {},
   "source": [
    "#Q4\n",
    "\n",
    "i) A histogram is a graphical representation of data points organized into user-specified ranges. Similar in appearance to a bar graph, the histogram condenses a data series into an easily interpreted visual by taking many data points and grouping them into logical ranges or bins.\n",
    "Histograms are commonly used in statistics to demonstrate how many of a certain type of variable occur within a specific range.\n",
    "\n",
    "For example, a census focused on the demography of a town may use a histogram to show how many people are between the ages of zero - 10, 11 - 20, 21 - 30, 31 - 40, 41 - 50, 51 -60, 61 - 70, and 71 - 80.\n",
    "\n",
    "This histogram example would look similar to the chart below. Let's say the numerals along the vertical access represent thousands of people. To read this histogram example, you can start with the horizontal axis and see that, beginning on the left, there are approximately 500 people in the town who are from less than one year old to 10 years old. There are 4,000 people in town who are 11 to 20 years old. And so on.\n",
    "\n",
    "Histograms can be customized in several ways by analysts. They can change the interval between buckets. In the example referenced above, there are eight buckets with an interval of ten. This could be changed to four buckets with an interval of 20.\n",
    "\n",
    "Another way to customize a histogram is to redefine the y-axis. The most basic label used is the frequency of occurrences observed in the data. However, one could also use percentage of total or density instead.\n",
    "\n",
    "ii) Scatter plots are used to plot data points on a horizontal and a vertical axis in the attempt to show how much one variable is affected by another. Each row in the data table is represented by a marker whose position depends on its values in the columns set on the X and Y axes.\n",
    "\n",
    "A third variable can be set to correspond to the color or size of the markers, thus adding yet another dimension to the plot.  \n",
    "\n",
    "The relationship between two variables is called their correlation. If the markers are close to making a straight line in the scatter plot, the two variables have a high correlation. If the markers are equally distributed in the scatter plot, the correlation is low, or zero. However, even though a correlation may seem to be present, this might not always be the case. Both variables could be related to some third variable, thus explaining their variation, or, pure coincidence might cause an apparent correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a4d9e",
   "metadata": {},
   "source": [
    "#Q5\n",
    "\n",
    "Data analysis is important in business to understand problems facing an organisation, and to explore data in meaningful ways. Data in itself is merely facts and figures. Data analysis organises, interprets, structures and presents the data into useful information that provides context for the data.\n",
    "\n",
    "Qualitative and quantitative data can be used to complement one another by adding words to numbers and vice versa. This helps with the interpretation and understanding of results. Using qualitative and quantitative data together can create new lines of thinking by offering different and fresh perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e99787",
   "metadata": {},
   "source": [
    "#Q6\n",
    "\n",
    "Bell-shaped: A bell-shaped picture, shown below, usually presents a normal distribution.\n",
    "    Bimodal: A bimodal shape, shown below, has two peaks. This shape may show that the data has come from two different systems. If this shape occurs, the two sources should be separated and analyzed separately.\n",
    "        Skewed right: Some histograms will show a skewed distribution to the right, as shown below. A distribution skewed to the right is said to be positively skewed. This kind of distribution has a large number of occurrences in the lower value cells (left side) and few in the upper value cells (right side). A skewed distribution can result when data is gathered from a system with has a boundary such as zero. In other words, all the collected data has values greater than zero.\n",
    "            Skewed left: Some histograms will show a skewed distribution to the left, as shown below. A distribution skewed to the left is said to be negatively skewed. This kind of distribution has a large number of occurrences in the upper value cells (right side) and few in the lower value cells (left side). A skewed distribution can result when data is gathered from a system with a boundary such as 100. In other words, all the collected data has values less than 100.\n",
    "                Uniform: A uniform distribution, as shown below, provides little information about the system. An example would be a state lottery, in which each class has about the same number of elements. It may describe a distribution which has several modes (peaks). If your histogram has this shape, check to see if several sources of variation have been combined. If so, analyze them separately. If multiple sources of variation do not seem to be the cause of this pattern, different groupings can be tried to see if a more useful pattern results. This could be as simple as changing the starting and ending points of the cells, or changing the number of cells. A uniform distribution often means that the number of classes is too small.\n",
    "                    Random: A random distribution, as shown below, has no apparent pattern. Like the uniform distribution, it may describe a distribution that has several modes (peaks). If your histogram has this shape, check to see if several sources of variation have been combined. If so, analyze them separately. If multiple sources of variation do not seem to be the cause of this pattern, different groupings can be tried to see if a more useful pattern results. This could be as simple as changing the starting and ending points of the cells, or changing the number of cells. A random distribution often means there are too many classes.\n",
    "                    \n",
    "                    Bins are equally-spaced intervals that are used to sort data on graphs. By default, the number of values in each bin is represented by bars on histograms and by stacks of dots on dotplots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5bbe9",
   "metadata": {},
   "source": [
    "#Q7\n",
    "\n",
    "5 ways to deal with outliers in data\n",
    "Set up a filter in your testing tool. Even though this has a little cost, filtering out outliers is worth it.\n",
    "Remove or change outliers during post-test analysis. \n",
    "Change the value of outliers. \n",
    "Consider the underlying distribution. \n",
    "Consider the value of mild outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad300e",
   "metadata": {},
   "source": [
    "#Q8\n",
    "\n",
    "A measure of central tendency is an important aspect of quantitative data. It is an estimate of a “typical” value. Three of the many ways to measure central tendency are the mean, median and mode. There are other measures, such as a trimmed mean, that we do not discuss here.\n",
    "Mean is like an average of a given number. It sums up the numbers and divides them with the count of numbers which provides us with the mean. On the other hand, the median returns the middle number from the whole data set, if even. It adds the two middle numbers and divides them by 2, giving us the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac63f7c",
   "metadata": {},
   "source": [
    "#Q9\n",
    "\n",
    "Why is a scatter plot used for bivariate data?\n",
    "Sometimes when we are given data, we find that there is a correlation between two variables, such as the score they achieve on a test and the amount of hours they spent studying. Scatterplots are used to determine whether such a correlation exists by mapping out the points on the graph.\n",
    "If there is a regression line on a scatter plot, you can identify outliers. An outlier for a scatter plot is the point or points that are farthest from the regression line. There is at least one outlier on a scatter plot in most cases, and there is usually only one outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e567817",
   "metadata": {},
   "source": [
    "#Q10\n",
    "\n",
    "Cross tabulation is a method to quantitatively analyze the relationship between multiple variables. Also known as contingency tables or cross tabs, cross tabulation groups variables to understand the correlation between different variables. It also shows how correlations change from one variable grouping to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446153ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

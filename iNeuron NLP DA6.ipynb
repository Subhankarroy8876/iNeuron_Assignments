{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd19b67",
   "metadata": {},
   "source": [
    "#Q1\n",
    "\n",
    "In its simplest form, the autoencoder is a three layers net, i.e. a neural net with one hidden layer. The input and output are the same, and we learn how to reconstruct the input, for example using the adam optimizer and the mean squared error loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be8d4e8",
   "metadata": {},
   "source": [
    "#Q2\n",
    "\n",
    "A sparse autoencoder is one of a range of types of autoencoder artificial neural networks that work on the principle of unsupervised machine learning. Autoencoders are a type of deep network that can be used for dimensionality reduction â€“ and to reconstruct a model through backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275f2b7",
   "metadata": {},
   "source": [
    "#Q3\n",
    "\n",
    "A denoising autoencoder is a specific type of autoencoder, which is generally classed as a type of deep neural network. The denoising autoencoder gets trained to use a hidden layer to reconstruct a particular model based on its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5864bd",
   "metadata": {},
   "source": [
    "#Q4\n",
    "\n",
    "Convolutional autoencoders (CAEs) are unsupervised dimensionality reduction models composed by convolutional layers capable of creating compressed image representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06af011",
   "metadata": {},
   "source": [
    "#Q5\n",
    "\n",
    "Stacked Autoencoders is a kind of unsupervised learning structure that owns three layers: input layer, hidden layer, and output layer. The process of an autoencoder training consists of two parts: encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f800312",
   "metadata": {},
   "source": [
    "#Q6\n",
    "\n",
    "The dropout removes inputs to a layer to reduce overfitting. Adding RepeatVector to the layer means it repeats the input n number of times. The TimeDistibuted layer takes the information from the previous layer and creates a vector with a length of the output layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464e23e",
   "metadata": {},
   "source": [
    "#Q7\n",
    "\n",
    "Extractive summarization aims at identifying the salient information that is then extracted and grouped together to form a concise summary. Abstractive summary generation rewrites the entire document by building internal semantic representation, and then a summary is created using natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb3a32",
   "metadata": {},
   "source": [
    "#Q8\n",
    "\n",
    "Abstractive summarization, on the other hand is a technique in which the summary is generated by generating novel sentences by either rephrasing or using the new words, instead of simply extracting the important sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9654fae",
   "metadata": {},
   "source": [
    "#Q9\n",
    "\n",
    "In computer science, beam search is a heuristic search algorithm that explores a graph by expanding the most promising node in a limited set. Beam search is an optimization of best-first search that reduces its memory requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5098d",
   "metadata": {},
   "source": [
    "#Q10\n",
    "\n",
    "Document length normalization adjusts the term frequency or the relevance score in order to normalize the effect of document length on the document ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f60856",
   "metadata": {},
   "source": [
    "#Q12\n",
    "\n",
    "ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It is essentially a set of metrics for evaluating automatic summarization of texts as well as machine translations. It works by comparing an automatically produced summary or translation against a set of reference summaries (typically human-produced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746f44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
